{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mathrochaa/faculdade/blob/main/PERCEPTRON_AND_OR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron -- Portas lógicas (AND, OR)\n",
        "\n",
        "Exemplo extraído de: https://medium.com/@alef.mattias/criando-um-perceptron-do-zero-com-python-f23bba2375bf\n",
        "\n",
        "Título: **Criando um Perceptron do zero com Python** por Alef Matias"
      ],
      "metadata": {
        "id": "bSXwL-_SgW-G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6NDw089gAKW",
        "outputId": "e186d5e4-4131-49be-971d-f3c5c19e8cf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "Treinando para a porta OR:\n",
            "0 0 -> 0\n",
            "0 1 -> 1\n",
            "1 0 -> 1\n",
            "1 1 -> 1\n",
            " \n",
            "\n",
            "Pesos treinados para OR: (np.float64(2.7275010840321703), np.float64(2.5027385495064682), np.float64(-0.6364328312420843))\n",
            "\n",
            "Testando o perceptron para OR:\n",
            "0 0 -> 0 (Esperado: 0 )\n",
            "0 1 -> 1 (Esperado: 1 )\n",
            "1 0 -> 1 (Esperado: 1 )\n",
            "1 1 -> 1 (Esperado: 1 )\n"
          ]
        }
      ],
      "source": [
        "# import -> incorpora uma biblioteca \\\n",
        "# (código já escrito para resolver algum problema específico)\n",
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    # Declaração do construtor da classe\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def train(self, inputs, outputs, learning_rate=0.1, epochs=100):\n",
        "        self.inputs = inputs\n",
        "        self.outputs = outputs\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "        # Inicialização de pesos iniciais de forma aleatória\n",
        "        w1, w2, bias = np.random.uniform(-1, 1), np.random.uniform(-1, 1), np.random.uniform(-1, 1)\n",
        "\n",
        "        for i in range(epochs):\n",
        "            for j in range(len(inputs)):\n",
        "                # função de ativação Sigmoid\n",
        "                sigmoid = 1 / (1 + np.exp(-(w1 * inputs[j][0] + w2 * inputs[j][1] + bias)))\n",
        "\n",
        "                # atualização dos pesos por iteração\n",
        "                w1 = w1 + learning_rate * (outputs[j][0] - sigmoid) * inputs[j][0]\n",
        "                w2 = w2 + learning_rate * (outputs[j][0] - sigmoid) * inputs[j][1]\n",
        "                bias = bias + (learning_rate * (outputs[j] [0] - sigmoid))\n",
        "\n",
        "        return w1, w2, bias\n",
        "\n",
        "    def predict(self, weights, x1, x2):\n",
        "        # Podemos usar FUNÇÃO DEGRAU OU FUNÇÃO SIGMOID\n",
        "        # Sigmoid = deveolve um se o resultado for maior do que 0.5, senão 0\n",
        "        return 1 if 1 / (1 + np.exp(- ((x1 * weights[0])\n",
        "        + (x2 * weights[1]) + weights[2]))) > 0.5 else 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Entradas das portas lógicas (em pares)\n",
        "    inputs_or = [[0,0], [0,1], [1,0], [1,1]]\n",
        "    outputs_or = [[0], [1], [1], [1]]\n",
        "\n",
        "    print(' ')\n",
        "    print(\"Treinando para a porta OR:\")\n",
        "    for i in range(len(inputs_or)):\n",
        "        print(inputs_or[i][0], inputs_or[i][1], '->', outputs_or[i][0])\n",
        "\n",
        "    print( ' ')\n",
        "\n",
        "    perceptron_or = Perceptron()\n",
        "\n",
        "    # Treinando o perceptron para OR\n",
        "    weights_or = perceptron_or.train(inputs = inputs_or,\n",
        "                                    outputs = outputs_or,\n",
        "                                    learning_rate=0.1, epochs=100)\n",
        "\n",
        "    print(\"\\nPesos treinados para OR:\", weights_or)\n",
        "\n",
        "    print(\"\\nTestando o perceptron para OR:\")\n",
        "    for i in range(len(inputs_or)):\n",
        "        prediction_or = perceptron_or.predict(weights_or, inputs_or[i][0], inputs_or[i][1])\n",
        "        print(inputs_or[i][0], inputs_or[i][1], '->', prediction_or, \"(Esperado:\", outputs_or[i][0], \")\")\n",
        "\n",
        "    # Exemplo de predição individual\n",
        "    # prediction = perceptron.predict(tanning, 1, 1)\n",
        "    # print('OUTPUT ', prediction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    print(i, end=\",\")\n",
        "\n",
        "a = [1, 2, 4, 5, 6]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKEaCbxtq3U1",
        "outputId": "6e3a2ec9-fb3b-4602-c1e7-3b797080003e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,"
          ]
        }
      ]
    }
  ]
}